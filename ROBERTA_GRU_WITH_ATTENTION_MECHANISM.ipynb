{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d03Kkff8kCZ4",
        "outputId": "2ad509c9-8aa5-4574-b296-4f4298604c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Dropout, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel"
      ],
      "metadata": {
        "id": "cO57bEZ5kDbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = '/content/drive/My Drive/Drug review/drugsComTrain_raw.csv'\n",
        "test_file_path = '/content/drive/My Drive/Drug review/drugsComTest_raw.csv'\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "data = pd.concat([train_data, test_data])"
      ],
      "metadata": {
        "id": "c2rFADLKlXcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I | re.A)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text"
      ],
      "metadata": {
        "id": "rMw4V5VDHpD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preprocess the reviews\n",
        "data['clean_review'] = data['review'].apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTXjVOXHODGL",
        "outputId": "3f77034c-14b7-4b15-d00e-5b2511984e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RoBERTa Tokenizer and Model\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = TFRobertaModel.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0DXWJPw_u2n",
        "outputId": "f64b12e3-e783-486f-b300-f7ce47364881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_features_batch(texts, batch_size=32):\n",
        "    all_features = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = roberta_tokenizer(batch_texts, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
        "        outputs = roberta_model(inputs['input_ids'])[0]  # Use last hidden state\n",
        "        batch_features = tf.reduce_mean(outputs, axis=1)  # Mean pooling\n",
        "        all_features.append(batch_features)\n",
        "    return tf.concat(all_features, axis=0)\n",
        "\n",
        "X_roberta_features = roberta_features_batch(data['clean_review'].tolist())"
      ],
      "metadata": {
        "id": "4AqX-phK_xKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Self-Attention layer\n",
        "class SelfAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SelfAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], input_shape[-1]), initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[-1],), initializer='zeros', trainable=True)\n",
        "        super(SelfAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        u = tf.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "        a = tf.nn.softmax(u, axis=1)\n",
        "        output = tf.reduce_sum(a * x, axis=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "SyrqvPNeOR3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build and compile GRU model with self-attention\n",
        "def build_gru_model(input_shape, output_units, loss, activation='softmax'):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        tf.keras.layers.GRU(units=128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
        "        SelfAttention(),\n",
        "        tf.keras.layers.Dense(output_units, activation=activation)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(), loss=loss, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "vMHoNNRdOZNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the target variable\n",
        "le_condition = LabelEncoder()\n",
        "y_condition = le_condition.fit_transform(data['condition'])"
      ],
      "metadata": {
        "id": "04RMs07iO_pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Convert input_ids and attention_mask to NumPy arrays if they are TensorFlow tensors\n",
        "input_ids_np = input_ids.numpy() if isinstance(input_ids, tf.Tensor) else input_ids\n",
        "attention_mask_np = attention_mask.numpy() if isinstance(attention_mask, tf.Tensor) else attention_mask\n",
        "\n",
        "# Convert target variable to NumPy array\n",
        "y_condition_np = np.array(y_condition)\n",
        "\n",
        "# Ensure all data is in the same format\n",
        "input_ids_np = np.array(input_ids_np)\n",
        "attention_mask_np = np.array(attention_mask_np)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, attention_mask_train, attention_mask_test, y_train, y_test = train_test_split(\n",
        "    input_ids_np, attention_mask_np, y_condition_np, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert y_train and y_test to categorical if needed\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "07E0Eu6HPCeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the model for condition prediction\n",
        "model_condition = build_gru_model(output_dim=100, output_units=y_train.shape[1], loss='categorical_crossentropy')\n",
        "history_condition = model_condition.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "id": "7mEHwAhhPEtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model for condition prediction\n",
        "y_pred_condition = model_condition.predict(X_test)\n",
        "y_pred_condition_classes = np.argmax(y_pred_condition, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "print('Classification Report for Condition Prediction:\\n', classification_report(y_test_classes, y_pred_condition_classes))\n",
        "print('Confusion Matrix for Condition Prediction:\\n', confusion_matrix(y_test_classes, y_pred_condition_classes))"
      ],
      "metadata": {
        "id": "jconArR8PHiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 02: Estimating drug ratings from reviews (Regression)\n",
        "y_rating = data['rating']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_rating, test_size=0.2, random_state=42)\n",
        "model_rating = build_gru_model(output_dim=100, output_units=1, loss='mean_squared_error', activation='linear')\n",
        "history_rating = model_rating.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "y_pred_rating = model_rating.predict(X_test)\n",
        "print('Mean Squared Error for Rating Prediction:', mean_squared_error(y_test, y_pred_rating))"
      ],
      "metadata": {
        "id": "tyoRg94aSi4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 03: Identifying elements that make reviews helpful (Linear Regression)\n",
        "data['usefulCount'] = data['usefulCount'].fillna(0).astype(int)\n",
        "y_helpful = data['usefulCount']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_helpful, test_size=0.2, random_state=42)\n",
        "model_helpful = build_gru_model(output_dim=100, output_units=1, loss='mean_squared_error', activation='linear')\n",
        "history_helpful = model_helpful.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "y_pred_helpful = model_helpful.predict(X_test)\n",
        "print('Mean Squared Error for Helpful Prediction:', mean_squared_error(y_test, y_pred_helpful))"
      ],
      "metadata": {
        "id": "91VcBra9TL7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map ratings to sentiments\n",
        "def get_sentiment(score):\n",
        "    if score >= 7:\n",
        "        return 2  # Positive\n",
        "    elif score <= 4:\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return 1  # Neutral\n",
        "\n",
        "# Add sentiment column to the data\n",
        "data['sentiment'] = data['rating'].apply(get_sentiment)\n",
        "y_sentiment = data['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_sentiment, test_size=0.2, random_state=42)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Build and train the model for sentiment analysis\n",
        "model_sentiment = build_gru_model(output_dim=100, output_units=y_train.shape[1], loss='categorical_crossentropy')\n",
        "history_sentiment = model_sentiment.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model for sentiment analysis\n",
        "y_pred_sentiment = model_sentiment.predict(X_test)\n",
        "y_pred_sentiment_classes = np.argmax(y_pred_sentiment, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "print('Classification Report for Sentiment Analysis:\\n', classification_report(y_test_classes, y_pred_sentiment_classes))"
      ],
      "metadata": {
        "id": "52N7HEZDWUs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 05: Classifying reviews as positive, negative, or neutral (Classification)\n",
        "y_sentiment = data['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_sentiment, test_size=0.2, random_state=42)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "model_sentiment = build_gru_model(output_dim=100, output_units=y_train.shape[1], loss='categorical_crossentropy')\n",
        "history_sentiment = model_sentiment.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "y_pred_sentiment = model_sentiment.predict(X_test)\n",
        "y_pred_sentiment_classes = np.argmax(y_pred_sentiment, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "print('Classification Report for Sentiment Classification:\\n', classification_report(y_test_classes, y_pred_sentiment_classes))\n",
        "print('Confusion Matrix for Sentiment Classification:\\n', confusion_matrix(y_test_classes, y_pred_sentiment_classes))\n",
        "print('Accuracy for Sentiment Classification:', accuracy_score(y_test_classes, y_pred_sentiment_classes))"
      ],
      "metadata": {
        "id": "XeYkiJ7cWVmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "def plot_training_history(history, title):\n",
        "    plt.plot(history.history['accuracy'], label='accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history_sentiment, 'Sentiment Classification Accuracy')"
      ],
      "metadata": {
        "id": "n26E-JjRWZQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 06: Exploring drugs and its associated conditions (Filtering)\n",
        "def explore_drug(drug_name):\n",
        "    filtered_data = data[data['drugName'].str.contains(drug_name, case=False, na=False)]\n",
        "    if filtered_data.empty:\n",
        "        print(f\"No data found for drug: {drug_name}\")\n",
        "        return pd.DataFrame()\n",
        "    return filtered_data[['drugName', 'condition', 'review', 'rating']]"
      ],
      "metadata": {
        "id": "YconnWeSWbvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "explored_drug = explore_drug('aspirin')\n",
        "if not explored_drug.empty:\n",
        "    print(explored_drug.head())"
      ],
      "metadata": {
        "id": "ZavpX2ZVWeA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distribution of conditions and ratings for a specific drug\n",
        "def plot_drug_distribution(drug_name):\n",
        "    filtered_data = explore_drug(drug_name)\n",
        "    if filtered_data.empty:\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    filtered_data['condition'].value_counts().plot(kind='bar')\n",
        "    plt.title(f'Condition Distribution for {drug_name}')\n",
        "    plt.xlabel('Condition')\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    filtered_data['rating'].value_counts().sort_index().plot(kind='bar')\n",
        "    plt.title(f'Rating Distribution for {drug_name}')\n",
        "    plt.xlabel('Rating')\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_drug_distribution('aspirin')"
      ],
      "metadata": {
        "id": "7jwGqQIuWgXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Preprocess the reviews for topic modeling\n",
        "data['clean_review'] = data['review'].apply(preprocess_text)\n",
        "reviews_clean = [review.split() for review in data['clean_review']]\n",
        "\n",
        "# Create a Gensim dictionary and corpus\n",
        "dictionary = Dictionary(reviews_clean)\n",
        "corpus = [dictionary.doc2bow(review) for review in reviews_clean]\n",
        "\n",
        "# Train an LDA model\n",
        "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)"
      ],
      "metadata": {
        "id": "z00xzkkXX1f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_reason(review_text):\n",
        "    # Implement your logic to identify the reason for a negative review\n",
        "    # This is a placeholder implementation\n",
        "    negative_keywords = ['side effect', 'not effective', 'bad experience', 'expensive', 'poor quality']\n",
        "    for keyword in negative_keywords:\n",
        "        if keyword in review_text.lower():\n",
        "            return keyword\n",
        "    return \"General dissatisfaction\""
      ],
      "metadata": {
        "id": "sq7rn-2fg2jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the necessary functions for main\n",
        "def predict_rating(review_text, rating_model, tokenizer, maxlen):\n",
        "    review_seq = tokenizer.texts_to_sequences([review_text])\n",
        "    review_pad = pad_sequences(review_seq, maxlen=maxlen, padding='post')\n",
        "    predicted_rating = rating_model.predict(review_pad)\n",
        "    return predicted_rating[0][0]\n",
        "\n",
        "def predict_sentiment(review_text, sentiment_model, tokenizer, maxlen):\n",
        "    review_seq = tokenizer.texts_to_sequences([review_text])\n",
        "    review_pad = pad_sequences(review_seq, maxlen=maxlen, padding='post')\n",
        "    predicted_sentiment = sentiment_model.predict(review_pad)\n",
        "    sentiment_class = np.argmax(predicted_sentiment, axis=1)[0]\n",
        "    return ['Negative', 'Neutral', 'Positive'][sentiment_class]\n",
        "\n",
        "def predict_drug_info(drug_name, train_df, test_df, rating_model, sentiment_model, tokenizer, maxlen, label_encoder, dictionary, lda_model):\n",
        "    # Filtering and merging data\n",
        "    drug_data = pd.concat([train_df, test_df])\n",
        "    filtered_data = drug_data[drug_data['drugName'].str.contains(drug_name, case=False, na=False)]\n",
        "\n",
        "    # Predicting conditions\n",
        "    conditions = filtered_data['condition'].unique().tolist()\n",
        "\n",
        "    # Predicting ratings and sentiments for each review\n",
        "    filtered_data['predicted_rating'] = filtered_data['review'].apply(lambda x: predict_rating(x, rating_model, tokenizer, maxlen))\n",
        "    filtered_data['predicted_sentiment'] = filtered_data['review'].apply(lambda x: predict_sentiment(x, sentiment_model, tokenizer, maxlen))\n",
        "\n",
        "    # Extracting some reviews\n",
        "    reviews = filtered_data[['review', 'rating', 'predicted_rating', 'predicted_sentiment']].head(5)\n",
        "\n",
        "    # Topic modeling (LDA) to identify topics in reviews\n",
        "    reviews_clean = [preprocess_text(review) for review in filtered_data['review']]\n",
        "    reviews_bow = [dictionary.doc2bow(review.split()) for review in reviews_clean]\n",
        "    topics = lda_model.show_topics(num_words=4)\n",
        "\n",
        "    return conditions, reviews, topics\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        print(\"\\nWelcome to Drug Review Analysis System!\")\n",
        "        print(\"1. Analyze Rating of a Review\")\n",
        "        print(\"2. Get Drug Information\")\n",
        "        print(\"3. Reason behind negative review\")\n",
        "        print(\"4. Exit\")\n",
        "        choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            review_text = input(\"Enter your review text: \")\n",
        "            rating = predict_rating(review_text, model_rating, tokenizer, maxlen)\n",
        "            sentiment = predict_sentiment(review_text, model_sentiment, tokenizer, maxlen)\n",
        "            print(f\"Predicted Rating: {rating:.2f}\")\n",
        "            print(f\"Predicted Sentiment: {sentiment}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            drug_name = input(\"Enter the name of the drug: \")\n",
        "            conditions, reviews, topics = predict_drug_info(drug_name, train_data, test_data, model_rating, model_sentiment, tokenizer, maxlen, le_condition, dictionary, lda_model)\n",
        "\n",
        "            print(f\"\\nConditions for using {drug_name}:\")\n",
        "            for condition in conditions:\n",
        "                print(f\"- {condition}\")\n",
        "\n",
        "            print(f\"\\nSome Reviews for {drug_name}:\")\n",
        "            for index, row in reviews.iterrows():\n",
        "                print(f\"Review {index + 1}:\")\n",
        "                print(f\"Rating: {row['rating']}\")\n",
        "                print(f\"Predicted Rating: {row['predicted_rating']:.2f}\")\n",
        "                print(f\"Predicted Sentiment: {row['predicted_sentiment']}\")\n",
        "                print(f\"Review: {row['review']}\")\n",
        "                print()\n",
        "\n",
        "            print(\"Topics in Reviews:\")\n",
        "            for topic in topics:\n",
        "                print(topic)\n",
        "\n",
        "        elif choice == '3':\n",
        "            review_text = input(\"Enter your review text: \")\n",
        "            sentiment = predict_sentiment(review_text, model_sentiment, tokenizer, 200)\n",
        "            if sentiment == 'Negative':\n",
        "                reason = identify_reason(review_text)\n",
        "                print(f\"Reason for Negative Review: {reason}\")\n",
        "            else:\n",
        "                print(\"The review is not negative.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"Exiting the program...\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1, 2, 3, or 4.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "I3IKgt1GXLdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}